{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb48e023-f5d3-4a4a-871d-b48ab4dec71a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# <center> STOCK PRICE DEEP LEARNING PREDICTION\n",
    "#### <center> RNN(Recurrent Neural Network) - LSTM(Long Short Term Memory) -  GRU(Gated Recurrent Unit) </center>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38c62278-ea4f-4c5d-9798-41b334e9c8b9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# A. Theory - Deep Learning Strategies for Time Series Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ffcf5d5-64a8-472d-bff6-4f8946b0c34a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### LTSM (Long Short-Term Memory Networks)\n",
    "\n",
    "Reference: [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "\n",
    "Long Short-Term Memory models are extremely powerful time-series models. \n",
    "Long Short Term Memory networks – usually just called “LSTMs” – are a special kind of RNN, capable of learning long-term dependencies. They can predict an arbitrary number of steps into the future. An LSTM module (or cell) has 5 essential components which allows it to model both long-term and short-term data.\n",
    "\n",
    "* Cell state (ct) - This represents the internal memory of the cell which stores both short term memory and long-term memories\n",
    "* Hidden state (ht) - This is output state information calculated w.r.t. current input, previous hidden state and current cell input which you eventually use to predict the future stock market prices. Additionally, the hidden state can decide to only retrive the short or long-term or both types of memory stored in the cell state to make the next prediction.\n",
    "* Input gate (it) - Decides how much information from current input flows to the cell state\n",
    "* Forget gate (ft) - Decides how much information from the current input and the previous cell state flows into the current cell state\n",
    "* Output gate (ot) - Decides how much information from the current cell state flows into the hidden state, so that if needed LSTM can only pick the long-term memories or short-term memories and long-term memories\n",
    "\n",
    "Try to predict stock price movement, not the exact stock value\n",
    "\n",
    "![LTSM states](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1523953369/lstm_xszk4d.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "311b1c74-6919-430d-a889-15b03080d4c3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53e29e91-aa0b-4214-9a85-4df2d4dc1f61",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f73e3d64-3de8-4713-8367-06603cfae0f7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# B. Apply Deep Learning Strategies for Stock Price Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e459f577-4590-4bb0-afd8-9f60347b6945",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import math\n",
    "from scipy import stats\n",
    "import pandas_ta as ta\n",
    "# import talib\n",
    "# from plot_stock import *\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80479588-3b94-49d6-a9e4-14a817fdd425",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # import chart_studio.plotly as py\n",
    "# import plotly.io as pio\n",
    "# # import kaleido\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd955f2e-fb43-4763-af42-63549a293848",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "import seaborn as seabornInstance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.models import Sequential, load_model\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#import matplotlib.cbook as cbook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional, SimpleRNN\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn import metrics\n",
    "from math import sqrt\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report, confusion_matrix, mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "#from sklearn.metrics import val_mean_absolute_percentage_error\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e435630-e54d-45b0-b249-7fd0818d719b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## I. Data Preprocessing\n",
    "\n",
    "* Step 1: Load stock price data from yfinance\n",
    "* Step 2: Split data based on Closing price to Training set and Testing Set (80% - 20%)\n",
    "* Step 3: Scale data with MinMax Scaler so every points failed in range (0, 1)\n",
    "* Step 4: Split the training set to every 30 days of training data and validation on the next 1 day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54a1e994-248f-4408-b232-034e45cb6b1f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def draw_candlestick_price(ticker, df, shorter_window, longer_window, is_static=False):\n",
    "    # Calculate and define moving average of window1 periods\n",
    "    avg1 = df.Close.rolling(window=shorter_window, min_periods=1).mean()\n",
    "\n",
    "    # Calculate and define moving average of window2 periods\n",
    "    avg2 = df.Close.rolling(window=longer_window, min_periods=1).mean()\n",
    "        \n",
    "    \n",
    "    # Construct a 2 x 1 Plotly figure\n",
    "    fig = make_subplots(rows=1, cols=1, specs=[[{\"secondary_y\": True}]])\n",
    "    \n",
    "    # Add Volume\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=df.index, y=df.Volume,\n",
    "                       name='Volume', opacity=0.8), row=1, col=1, secondary_y=True\n",
    "    )\n",
    "    \n",
    "    # Candlestick chart for pricing\n",
    "    fig.add_trace(\n",
    "        go.Candlestick(\n",
    "            x=df.index,\n",
    "            open=df['Open'],\n",
    "            high=df['High'],\n",
    "            low=df['Low'],\n",
    "            close=df['Close'],\n",
    "            name=ticker,\n",
    "            increasing_line_color='#ff9900',\n",
    "            decreasing_line_color='black',\n",
    "            showlegend=True\n",
    "        ), row=1, col=1, secondary_y=False,\n",
    "    )\n",
    "    \n",
    "    # Moving Average line chart\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df.index, y=avg1, name=f'MA{shorter_window}'),secondary_y=False)\n",
    "    fig.add_trace(\n",
    "          go.Scatter(x=df.index, y=avg2, name=f'MA{longer_window}'),secondary_y=False)\n",
    "        \n",
    "    # Make it pretty\n",
    "    layout = go.Layout(\n",
    "        plot_bgcolor='#efefef',\n",
    "        width=1000,\n",
    "        height=500,\n",
    "        # Font Families\n",
    "        font_family='Monospace',\n",
    "        font_color='#000000',\n",
    "        font_size=15,\n",
    "        xaxis=dict(\n",
    "            rangeslider=dict(\n",
    "                visible=False\n",
    "            )\n",
    "        ),\n",
    "        legend=dict( orientation='h',yanchor='middle', y=1.1, xanchor=\"left\", x=0.5),\n",
    "        hovermode='x',\n",
    "        hoverlabel=dict(font=dict(size=10))\n",
    "    )\n",
    "    # Update options and show plot\n",
    "    fig.update_layout(layout)\n",
    "    if not is_static:\n",
    "        fig.show()\n",
    "    else:\n",
    "        fig.show(renderer=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76495a0f-250b-48a8-b4b5-7acc88cc6c54",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class Stock:\n",
    "    '''\n",
    "    Python class to obtain, visualize and analyze stock price of any ticker \n",
    "    '''\n",
    "    # Step 1: Load data\n",
    "    def __init__(self, ticker, start_date, end_date=datetime.date.today() - relativedelta(days=1)):\n",
    "        self.ticker = ticker.upper()\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.df = yfinance.download(self.ticker, start=self.start_date, end=self.end_date)\n",
    "        #self.df['Capitalization'] = self.df['Adj Close'] * self.df['Volume']\n",
    "        \n",
    "    def draw_price_candlestick(self, window1, window2, is_static=False):\n",
    "        draw_candlestick_price(self.ticker, self.df, window1, window2, is_static)\n",
    "        \n",
    "    # Step 2: Split training and testing dataset\n",
    "    def split_data(self, training_size):\n",
    "        training_index = round(self.df.shape[0]*training_size)\n",
    "        testing_index = round(self.df.shape[0]*training_size) + 1\n",
    "\n",
    "        self.training = self.df[:training_index].filter(['Close'])\n",
    "        self.testing = self.df[testing_index:].filter(['Close'])\n",
    "        print('# Records:', self.df.shape[0])\n",
    "        print(f'Training Dataset: 0 to {training_index}' )\n",
    "        print(f'Testing Dataset: {testing_index} to {self.df.shape[0]}' )\n",
    "        \n",
    "        ax = plt.axes()\n",
    "        plt.title('Dataset Training & Testing set for Prediction', color= 'BLACK',fontsize = 15,fontweight = \"bold\")\n",
    "        plt.xlabel('Date' , fontsize = 18,fontweight = \"bold\")\n",
    "        plt.ylabel(\"Closing Price USD ($)\" , fontsize = 10,fontweight = \"bold\")\n",
    "        plt.plot(self.training['Close'], 'blue', label='Training Data')\n",
    "        plt.plot(self.testing['Close'], 'red', label='Testing Data')\n",
    "        #plt.xticks(np.arange(0,1857, 300), df['Date'][0:1857:300])\n",
    "        plt.legend()\n",
    "        #return self.training, self.testing\n",
    "    \n",
    "      \n",
    "    # Step 3: Scale data with MinMax Scaler so every points fell in range (0, 1)\n",
    "    # Step 4: Split the training set to every 30 days of training data and validation on the next 1 day \n",
    "\n",
    "    def process_data(self):\n",
    "        # scale training data\n",
    "        sc = MinMaxScaler(feature_range=(0,1))\n",
    "        training_scaled = sc.fit_transform(self.training)\n",
    "\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        for i in range(30, len(training_scaled)):\n",
    "            X_train.append(training_scaled[i-30:i, 0])\n",
    "            y_train.append(training_scaled[i, 0])\n",
    "\n",
    "        X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "        self.X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "        self.y_train = y_train\n",
    "        print('X train reshape', self.X_train.shape, '| Y train shape', self.y_train.shape)\n",
    "        print('Number of Training Sample:', len(self.X_train), '\\n')\n",
    "#         print ('First Training Sample:')\n",
    "#         print ('Training on:\\n', self.X_train[1])\n",
    "#         print('Predict on:\\n', self.y_train[1],'\\n')\n",
    "\n",
    "        # scale testing data\n",
    "        print(\"---Scale testing data---\")\n",
    "        testing_scaled = sc.fit_transform(self.testing)\n",
    "\n",
    "        X_test = [] \n",
    "        for i in range(30, len(testing_scaled)):\n",
    "            X_test.append(testing_scaled[i-30:i, 0])  \n",
    "\n",
    "        X_test = np.array(X_test)\n",
    "        self.X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "        self.y_test = self.testing.iloc[30:, 0:].values\n",
    "        print('X test reshape', self.X_test.shape,'| Y test shape', self.y_test.shape)\n",
    "        return sc\n",
    "    \n",
    "    \n",
    "    def train_data(self, regressor, epochs=100, batch_size=64):\n",
    "        # Fitting to the training set\n",
    "        history = regressor.fit(self.X_train, self.y_train, epochs=epochs, batch_size=batch_size)\n",
    "        return regressor\n",
    "        \n",
    "    def predict(self, model, regressor, sc):\n",
    "        prediction = regressor.predict(self.X_test)\n",
    "        prediction = sc.inverse_transform(prediction)\n",
    "        \n",
    "        predicted_df = pd.DataFrame()\n",
    "        predicted_period = self.testing.tail(self.testing.shape[0]-30).index\n",
    "        predicted_df['period'] = predicted_period\n",
    "        predicted_df['Y'] = self.y_test\n",
    "        predicted_df['prediction'] = prediction\n",
    "        predicted_df = predicted_df.set_index('period')\n",
    "        return predicted_df\n",
    "    \n",
    "    def plot_model(self, model, predicted_df, is_static=False):\n",
    "        fig = make_subplots(rows=1, cols=1, specs=[[{\"secondary_y\": False}]])\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=predicted_df.index, y= predicted_df.Y, name='Y_true'))\n",
    "        fig.add_trace(\n",
    "              go.Scatter(x=predicted_df.index, y= predicted_df.prediction, name='Y_prediction'))\n",
    "\n",
    "        layout = go.Layout(\n",
    "        plot_bgcolor='#efefef',\n",
    "        width=1000,\n",
    "        height=500,\n",
    "        # Font Families\n",
    "        font_family='Monospace',\n",
    "        font_color='#000000',\n",
    "        font_size=15,\n",
    "        xaxis=dict(\n",
    "            rangeslider=dict(\n",
    "                visible=False\n",
    "            )\n",
    "        ),\n",
    "        legend=dict( orientation='h',yanchor='middle', y=1.1, xanchor=\"left\", x=0.5),\n",
    "        hovermode='x',\n",
    "        hoverlabel=dict(font=dict(size=10))\n",
    "        )\n",
    "        # Update options and show plot\n",
    "        fig.update_layout(layout)\n",
    "        if not is_static:\n",
    "            fig.show()\n",
    "        else:\n",
    "            fig.show(renderer=\"png\")\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c007295-8a3e-4a4c-b97f-9425c077926a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get 20 year from yesterday\n",
    "#start_date = datetime.date.today() - relativedelta(days=1) - relativedelta(years=20) \n",
    "start_date = datetime.datetime(2000,1,1)\n",
    "\n",
    "# Load data\n",
    "ticker = 'spy'\n",
    "stock = Stock(ticker, start_date)\n",
    "stock.draw_price_candlestick(50, 200)\n",
    "\n",
    "# Split data\n",
    "stock.split_data(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8d0052c-31d1-4124-8eca-f091c90ae887",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Process data\n",
    "sc = stock.process_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7671e6f-f459-4e4c-98fc-0f2e456a01e7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## II. Data Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef763b03-907c-4dc5-8620-1a04b595730b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1. Recurrent Neural Network (RNN) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c8066dd-49a6-4983-8c7a-9a880a3e4ff5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "regressorRNN = Sequential()\n",
    "regressorRNN.add(SimpleRNN(units=64, return_sequences=True, input_shape=(stock.X_train.shape[1],1)))\n",
    "regressorRNN.add(Dropout(0.2))\n",
    "regressorRNN.add(SimpleRNN(units=256))\n",
    "regressorRNN.add(Dropout(0.2))\n",
    "regressorRNN.add(Dense(units=1, activation='relu'))\n",
    "# Compiling the RNN\n",
    "regressorRNN.compile(optimizer='adam',loss='mean_squared_error', metrics=['mae','mse'])\n",
    "regressorRNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f24412b5-b186-4863-88f8-70294f22692d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "regressorRNN = stock.train_data(regressorRNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "562494a5-1157-48cb-9010-24ceaa495c6d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "RNN_Stock_Price_Prediction = stock.predict('RNN', regressorRNN, sc)\n",
    "RNN_Stock_Price_Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07923f26-40b7-48c2-8d85-db8bd4d193a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "stock.plot_model('RNN', RNN_Stock_Price_Prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec2d2093-0c7c-40e9-8b78-30390600e5fb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3. Long Short Term Memory Network (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4883010-ddfd-4339-9b17-648feb3c54cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "regressorLSTM = Sequential()\n",
    "regressorLSTM.add(LSTM(units=256, return_sequences=True, input_shape=(stock.X_train.shape[1],1)))\n",
    "regressorLSTM.add(Dropout(0.2))\n",
    "regressorLSTM.add(LSTM(units=128))\n",
    "regressorLSTM.add(Dropout(0.2))\n",
    "regressorLSTM.add(Dense(units=1))\n",
    "# Compiling the LSTM\n",
    "regressorLSTM.compile(optimizer='adam',loss='mean_squared_error', metrics=['mae','mse'])\n",
    "regressorLSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "362db0a5-f96b-47d1-91fc-590b646d9167",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "regressorLSTM = stock.train_data(regressorLSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06eeb78b-0f10-4b69-b25b-8d448f80ec3b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "LSTM_Stock_Price_Prediction = stock.predict('LSTM', regressorLSTM, sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb8ff84a-105c-46db-9294-6e30509d118c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "LSTM_Stock_Price_Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d1f3abb-39c2-4660-bae2-72ba886d0c1c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "stock.plot_model('LSTM', LSTM_Stock_Price_Prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ddcb953e-45cc-443c-a5ac-447c4a3b035a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4. Gated Recurrent Unit (GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec076fcf-556f-4042-a688-8a57f3ed9f66",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "regressorGRU = Sequential()\n",
    "regressorGRU.add(GRU(units=512, return_sequences=True, input_shape=(stock.X_train.shape[1],1)))\n",
    "regressorGRU.add(Dropout(0.2))\n",
    "regressorGRU.add(GRU(units=1024))\n",
    "regressorGRU.add(Dropout(0.2))\n",
    "regressorGRU.add(Dense(units=1))\n",
    "# Compiling the GRU\n",
    "regressorGRU.compile(optimizer='adam',loss='mean_squared_error', metrics=['mae','mse'])\n",
    "regressorGRU.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a981a729-6229-4219-825b-c8e79a23438a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "regressorGRU = stock.train_data(regressorGRU, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a066efa-ddfa-4ab4-8260-d141cea398cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "GRU_Stock_Price_Prediction = stock.predict('GRU', regressorGRU, sc)\n",
    "GRU_Stock_Price_Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2e7ca1e-50e8-4327-ae45-468f8df8769b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "stock.plot_model('GRU', GRU_Stock_Price_Prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a21df07-d8e0-4b8f-83a2-0af9930b635f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## III. Evaluate Model\n",
    "\n",
    "When dealing with regression models, it is very unlikely that our model will precisely predict the target variable, because the target variable can take on any real value. However, we would naturally like to understand how far away our predicted values are from the true values, so will we utilize a metric that takes into account the overall deviation (Reference: Machine Learning with Spark - Second Edition) \n",
    "\n",
    "**Mean Absolute Error (MAE)**: average of the absolute difference between predicted value and true value. The MAE measures the average magnitude of the errors in a set of forecasts, without considering their direction. The MAE is a linear score which means that all the individual differences are weighted equally in the average.\n",
    "\n",
    "![MAE](https://wikimedia.org/api/rest_v1/media/math/render/svg/3ef87b78a9af65e308cf4aa9acf6f203efbdeded)\n",
    "\n",
    "\n",
    "**Mean Square Error (MSE)**: is the sum of the square of the difference between the predicted and actual target variables, divided by the number of data points.\n",
    "\n",
    "![MSE](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781785889936/files/assets/image_07_002.jpg) \n",
    "\n",
    "\n",
    "**Root Mean Square Error (RMSE)**:  is the square root of RMSE which measures the average magnitude of the error. Since the errors are squared before they are averaged, the RMSE gives a relatively high weight to large errors. This means the RMSE is most useful when large errors are particularly undesirable. The MAE and the RMSE can be used together to diagnose the variation in the errors in a set of forecasts. The RMSE will always be larger or equal to the MAE; the greater difference between them, the greater the variance in the individual errors in the sample. If the RMSE=MAE, then all the errors are of the same magnitude\n",
    "\n",
    "![RMSE](https://www.gstatic.com/education/formulas2/397133473/en/root_mean_square_deviation.svg)\n",
    "\n",
    "\n",
    "**R square coefficient**: commonly used in statistics to measure how well the model fits the data, how much variance in the target can be explained by the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a91913c-4a65-4426-96ee-a16d712b9128",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "R_squared = [] \n",
    "MAE = [] # Mean Absolute Error\n",
    "MSE = [] # Mean Square Error\n",
    "RMSE = [] # Root Mean Square Error\n",
    "last_price = []\n",
    "last_prediction = []\n",
    "\n",
    "def evaluate_model(model, y_test, prediction):\n",
    "    r2 = metrics.r2_score(y_test, prediction)\n",
    "    mae = metrics.mean_absolute_error(y_test, prediction)\n",
    "    mse = metrics.mean_squared_error(y_test, prediction)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(y_test, prediction))\n",
    "    last_price.append(y_test[-1])\n",
    "    last_prediction.append(prediction[-1])\n",
    "    \n",
    "    models.append(model)\n",
    "    R_squared.append(r2)\n",
    "    MAE.append(mae)\n",
    "    MSE.append(mse)\n",
    "    RMSE.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "548ba088-7747-49a3-8233-dd5d0ac8b1e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "evaluate_model('RNN', RNN_Stock_Price_Prediction[\"Y\"], RNN_Stock_Price_Prediction[\"prediction\"])\n",
    "evaluate_model('LSTM', LSTM_Stock_Price_Prediction[\"Y\"], LSTM_Stock_Price_Prediction[\"prediction\"])\n",
    "evaluate_model('GRU', GRU_Stock_Price_Prediction[\"Y\"], GRU_Stock_Price_Prediction[\"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "356f1ffe-ac8c-4335-ba3e-3bbe43adcdab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def compare_model(models, R_squared, MAE, MSE, RMSE):\n",
    "    compared_models = pd.DataFrame()\n",
    "    compared_models['Models'] = models\n",
    "    compared_models['R_squared'] = R_squared\n",
    "    compared_models['MAE'] = MAE\n",
    "    compared_models['MSE'] = MSE\n",
    "    compared_models['RMSE'] = RMSE\n",
    "    compared_models['last_price'] = last_price\n",
    "    compared_models['last_prediction'] = last_prediction\n",
    "    \n",
    "    return compared_models\n",
    "    \n",
    "compare_model(models, R_squared, MAE, MSE, RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "872945e0-d19a-4001-8c78-182c740683a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Actual stock price\n",
    "stock.testing.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60937c88-c90d-4299-8efa-abdaa486d4d8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# C. Reference\n",
    "\n",
    "1. [Stock Prediction Using Deep Learning with Long Short Term Memory Networks - Carol Hargreaves, Leran Chen\n",
    "National University of Singapore](https://www.researchgate.net/publication/347515776_Stock_Prediction_Using_Deep_Learning_with_Long-Short-Term-Memory_Networks)  \n",
    "\n",
    "2. [Comparative Analysis of Recurrent Neural Networks in Stock Price Prediction for Different Frequency Domains](https://www.mdpi.com/1999-4893/14/8/251) \n",
    "\n",
    "2. [Stock Prediction with Long Short Term Memory Networks](https://www.researchgate.net/publication/347515776_Stock_Prediction_Using_Deep_Learning_with_Long-Short-Term-Memory_Networks)\n",
    "\n",
    "3. [Tutorial for LSTM in Python](https://www.datacamp.com/community/tutorials/lstm-python-stock-market)\n",
    "\n",
    "4. [LSTM Neural Network for Time Series Prediction - Jakob Aungiers](https://github.com/jaungiers/LSTM-Neural-Network-for-Time-Series-Prediction)\n",
    "\n",
    "5. [Technical Indicators and GRU/LSTM for Time-Series Prediction](https://towardsdatascience.com/forecasting-with-technical-indicators-and-gru-lstm-rnn-multivariate-time-series-a3244dcbc38b)\n",
    "\n",
    "6. [Deep Learning in Asset Pricing - Luyang Chen\n",
    ", Markus Pelger and Jason Zhu](https://economics.yale.edu/sites/default/files/deep_learning_in_asset_pricing.pdf)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "DeepLearningStrategy",
   "notebookOrigID": 230759278571831,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
